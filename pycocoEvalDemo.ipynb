{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__author__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n"
     ]
    }
   ],
   "source": [
    "import pycocotools\n",
    "print(dir(pycocotools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json\n",
    "import logging\n",
    "from typing import Any, Dict\n",
    "from PIL import Image\n",
    "import requests\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def from_json(labeled_data, coco_output, label_format='XY'):\n",
    "    \"Writes labelbox JSON export into MS COCO format.\"\n",
    "    # read labelbox JSON output\n",
    "    with open(labeled_data, 'r') as file_handle:\n",
    "        label_data = json.loads(file_handle.read())\n",
    "\n",
    "    # setup COCO dataset container and info\n",
    "    coco = make_coco_metadata(label_data[0]['Project Name'], label_data[0]['Created By'],)\n",
    "\n",
    "    for data in label_data:\n",
    "        # Download and get image name\n",
    "        try:\n",
    "            add_label(coco, data['ID'], data['Labeled Data'], data['Label'], label_format)\n",
    "        except requests.exceptions.MissingSchema as exc:\n",
    "            LOGGER.warning(exc)\n",
    "            continue\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            LOGGER.warning('Failed to fetch image from %s, skipping', data['Labeled Data'])\n",
    "            continue\n",
    "            \n",
    "    with open(coco_output, 'w+') as file_handle:\n",
    "        file_handle.write(json.dumps(coco))\n",
    "\n",
    "\n",
    "\n",
    "def make_coco_metadata(project_name: str, created_by: str) -> Dict[str, Any]:\n",
    "    \"\"\"Initializes COCO export data structure.\n",
    "    Args:\n",
    "        project_name: name of the project\n",
    "        created_by: email of the project creator\n",
    "    Returns:\n",
    "        The COCO export represented as a dictionary.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'info': {\n",
    "            'year': dt.datetime.now(dt.timezone.utc).year,\n",
    "            'version': None,\n",
    "            'description': project_name,\n",
    "            'contributor': created_by,\n",
    "            'url': 'labelbox.com',\n",
    "            'date_created': dt.datetime.now(dt.timezone.utc).isoformat()\n",
    "        },\n",
    "        'images': [],\n",
    "        'annotations': [],\n",
    "        'licenses': [],\n",
    "        'categories': []\n",
    "    }\n",
    "\n",
    "\n",
    "def add_label(\n",
    "        coco: Dict[str, Any], label_id: str, image_url: str,\n",
    "        labels: Dict[str, Any], label_format: str ):\n",
    "    \"\"\"Incrementally updates COCO export data structure with a new label.\n",
    "    Args:\n",
    "        coco: The current COCO export, will be incrementally updated by this method.\n",
    "        label_id: ID for the instance to write\n",
    "        image_url: URL to download image file from\n",
    "        labels: Labelbox formatted labels to use for generating annotation\n",
    "        label_format: Format of the labeled data. Valid options are: \"WKT\" and\n",
    "                      \"XY\", default is \"WKT\".\n",
    "    Returns:\n",
    "        The updated COCO export represented as a dictionary.\n",
    "    \"\"\"\n",
    "    image = {\n",
    "        \"id\": label_id,\n",
    "        \"file_name\": image_url,\n",
    "        \"license\": None,\n",
    "        \"flickr_url\": image_url,\n",
    "        \"coco_url\": image_url,\n",
    "        \"date_captured\": None,\n",
    "    }\n",
    "    response = requests.get(image_url, stream=True, timeout=1.0)\n",
    "    response.raw.decode_content = True\n",
    "    image['width'], image['height'] = Image.open(response.raw).size\n",
    "\n",
    "    coco['images'].append(image)\n",
    "\n",
    "    # remove classification labels (Skip, etc...)\n",
    "    if not callable(getattr(labels, 'keys', None)):\n",
    "        return\n",
    "\n",
    "    # convert label to COCO Polygon format\n",
    "    for category_name, label_data in labels.items():\n",
    "        try:\n",
    "            # check if label category exists in 'categories' field\n",
    "            category_id = [c['id']\n",
    "                           for c in coco['categories']\n",
    "                           if c['supercategory'] == category_name][0]\n",
    "        except IndexError:\n",
    "            category_id = len(coco['categories']) + 1\n",
    "            category = {\n",
    "                'supercategory': category_name,\n",
    "                'id': category_id,\n",
    "                'name': category_name\n",
    "            }\n",
    "            coco['categories'].append(category)\n",
    "\n",
    "        polygons = _get_polygons(label_format, label_data)\n",
    "        _append_polygons_as_annotations(coco, image, category_id, polygons)\n",
    "\n",
    "\n",
    "def _append_polygons_as_annotations(coco, image, category_id, polygons):\n",
    "    \"Adds `polygons` as annotations in the `coco` export\"\n",
    "    for polygon in polygons:\n",
    "        segmentation = []\n",
    "        for x_val, y_val in polygon.exterior.coords:\n",
    "            segmentation.extend([x_val, y_val])\n",
    "\n",
    "        annotation = {\n",
    "            \"id\": len(coco['annotations']) + 1,\n",
    "            \"image_id\": image['id'],\n",
    "            \"category_id\": category_id,\n",
    "            \"segmentation\": [segmentation],\n",
    "            \"area\": polygon.area,  # float\n",
    "            \"bbox\": [polygon.bounds[0], polygon.bounds[1],\n",
    "                     polygon.bounds[2] - polygon.bounds[0],\n",
    "                     polygon.bounds[3] - polygon.bounds[1]],\n",
    "            \"iscrowd\": 0\n",
    "        }\n",
    "        \n",
    "        coco['annotations'].append(annotation)\n",
    "\n",
    "\n",
    "def _get_polygons(label_format, label_data):\n",
    "    \"Converts segmentation `label: String!` into polygons\"\n",
    "    if label_format == 'WKT':\n",
    "        if isinstance(label_data, list):  # V3\n",
    "            polygons = map(lambda x: wkt.loads(x['geometry']), label_data)\n",
    "        else:  # V2\n",
    "            polygons = wkt.loads(label_data)\n",
    "    elif label_format == 'XY':\n",
    "        polygons = []\n",
    "        for xy_list in label_data:\n",
    "            if 'geometry' in xy_list:  # V3\n",
    "                xy_list = xy_list['geometry']\n",
    "\n",
    "                # V2 and V3\n",
    "                if not isinstance(xy_list, list):\n",
    "                    LOGGER.warning('Could not get an point list to construct polygon, skipping')\n",
    "                    continue\n",
    "            else:  # V2, or non-list\n",
    "                if not isinstance(xy_list, list) or not xy_list or 'x' not in xy_list[0]:\n",
    "                    # skip non xy lists\n",
    "                    LOGGER.warning('Could not get an point list to construct polygon, skipping')\n",
    "                    continue\n",
    "\n",
    "            if len(xy_list) > 2:  # need at least 3 points to make a polygon\n",
    "                polygons.append(Polygon(map(lambda p: (p['x'], p['y']), xy_list)))\n",
    "    else:\n",
    "        exc = UnknownFormatError(label_format=label_format)\n",
    "        LOGGER.exception(exc.message)\n",
    "        raise exc\n",
    "\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "rewrite of some functions to transform a ground truth file into a prediction file for quantification of human prediction \n",
    "vs machine predictions.\n",
    "\n",
    "output fmt of prediction file\n",
    "\n",
    "[{\"image_id\":42,\"category_id\":18,\"bbox\":[258.15,41.29,348.26,243.78],\"score\":0.236},\n",
    "{\"image_id\":73,\"category_id\":11,\"bbox\":[61,22.75,504,609.67],\"score\":0.318}, ... ,\n",
    "{\"image_id\":1292,\"category_id\":47,\"bbox\":[66.74,228.43,32.05,32.89],\"score\":0.097}]\n",
    "\"\"\"\n",
    "\n",
    "def generate_predfile(labeled_data, coco_annot_output, label_format='XY'):\n",
    "    \"Writes labelbox JSON export into MS COCO format.\"\n",
    "    # read labelbox JSON output\n",
    "    with open(labeled_data, 'r') as file_handle:\n",
    "        label_data = json.loads(file_handle.read())\n",
    "\n",
    "    \n",
    "    coco =[]\n",
    "    \n",
    "    categories = []\n",
    "    \n",
    "    for data in label_data:\n",
    "        # Download and get image name\n",
    "        try:\n",
    "            add_label2(coco, categories, data['ID'], data['Labeled Data'], data['Label'], label_format)\n",
    "        except requests.exceptions.MissingSchema as exc:\n",
    "            LOGGER.warning(exc)\n",
    "            continue\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            LOGGER.warning('Failed to fetch image from %s, skipping', data['Labeled Data'])\n",
    "            continue \n",
    "    with open(coco_annot_output, 'w+') as file_handle:\n",
    "        file_handle.write(json.dumps(coco))\n",
    "\n",
    "def add_label2(\n",
    "        coco: Dict[str, Any], categories , label_id: str, image_url: str,\n",
    "        labels: Dict[str, Any], label_format: str ):\n",
    "    \"\"\"Incrementally updates COCO export data structure with a new label.\n",
    "    Args:\n",
    "        coco: The current COCO export, will be incrementally updated by this method.\n",
    "        label_id: ID for the instance to write\n",
    "        image_url: URL to download image file from\n",
    "        labels: Labelbox formatted labels to use for generating annotation\n",
    "        label_format: Format of the labeled data. Valid options are: \"WKT\" and\n",
    "                      \"XY\", default is \"WKT\".\n",
    "    Returns:\n",
    "        The updated COCO export represented as a dictionary.\n",
    "    \"\"\"\n",
    "    image = {\n",
    "        \"id\": label_id,\n",
    "        \"file_name\": image_url,\n",
    "        \"license\": None,\n",
    "        \"flickr_url\": image_url,\n",
    "        \"coco_url\": image_url,\n",
    "        \"date_captured\": None,\n",
    "    }\n",
    "    # convert label to COCO Polygon format\n",
    "    for category_name, label_data in labels.items():\n",
    "        try:\n",
    "            # check if label category exists in 'categories' field\n",
    "            category_id = [c['id']\n",
    "                           for c in categories\n",
    "                           if c['supercategory'] == category_name][0]\n",
    "        except IndexError:\n",
    "            category_id = len(categories) + 1\n",
    "            category = {\n",
    "                'supercategory': category_name,\n",
    "                'id': category_id,\n",
    "                'name': category_name\n",
    "            }\n",
    "            categories.append(category)\n",
    "        \n",
    "        polygons = _get_polygons(label_format, label_data)\n",
    "        _append_polygons_as_annotations2(coco, image, category_id, polygons)\n",
    "        \n",
    "def _append_polygons_as_annotations2(coco, image, category_id, polygons):\n",
    "    \"Adds `polygons` as annotations in the `coco` export\"\n",
    "    for polygon in polygons:\n",
    "        segmentation = []\n",
    "        for x_val, y_val in polygon.exterior.coords:\n",
    "            segmentation.extend([x_val, y_val])        \n",
    "        annotation = {\"image_id\":image['id'],\"category_id\":category_id,\n",
    "                      \"bbox\":[polygon.bounds[0], polygon.bounds[1],\n",
    "                     polygon.bounds[2] - polygon.bounds[0],\n",
    "                     polygon.bounds[3] - polygon.bounds[1]],\"score\":1}\n",
    "        coco.append(annotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir='../comparison'\n",
    "json_name='testexport'\n",
    "json_output='testexportcoco'\n",
    "from_json('%s/%s.json'%(json_dir, json_name), '%s/%s.json'%(json_dir, json_output), label_format='XY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predfile('../comparison/testexport.json' , '../comparison/testexport_humanannot.json' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "#import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running demo for *bbox* results.\n"
     ]
    }
   ],
   "source": [
    "annType = 'bbox'     #specify type here\n",
    "print ('Running demo for *%s* results.'%(annType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.07s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#initialize COCO ground truth api\n",
    "dataDir='../comparison'\n",
    "dataType='testexportcoco'\n",
    "annFile = '%s/%s.json'%(dataDir,dataType)\n",
    "cocoGt=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#initialize COCO detections api --- fake .json files\n",
    "resFile='../comparison/testexport_humanannot.json'\n",
    "cocoDt=cocoGt.loadRes(resFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgIds=sorted(cocoGt.getImgIds())\n",
    "imgIds=imgIds[0:100]\n",
    "imgId = imgIds[np.random.randint(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=8.61s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.635\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n"
     ]
    }
   ],
   "source": [
    "# running evaluation\n",
    "cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
    "cocoEval.params.imgIds = imgIds\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
